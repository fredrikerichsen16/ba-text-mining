{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab1-Assignment\n",
    "\n",
    "Copyright: Vrije Universiteit Amsterdam, Faculty of Humanities, CLTL\n",
    "\n",
    "This notebook describes the assignment for Lab 1 of the text mining course. \n",
    "\n",
    "**Points**: each exercise is prefixed with the number of points you can obtain for the exercise.\n",
    "\n",
    "We assume you have worked through the following notebooks:\n",
    "* **Lab1.1-introduction**\n",
    "* **Lab1.2-introduction-to-NLTK**\n",
    "* **Lab1.3-introduction-to-spaCy** \n",
    "\n",
    "In this assignment, you will process an English text (**Lab1-apple-samsung-example.txt**) with both NLTK and spaCy and discuss the similarities and differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits\n",
    "The notebooks in this block have been originally created by [Marten Postma](https://martenpostma.github.io). Adaptations were made by [Filip Ilievski](http://ilievski.nl)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tip: how to read a file from disk\n",
    "Let's open the file **Lab1-apple-samsung-example.txt** from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/fredrik/Library/Mobile Documents/com~apple~CloudDocs/Skole/Text Mining/ba-text-mining-master/lab_sessions/lab1/Lab1-apple-samsung-example.txt\n",
      "does path exist? -> True\n"
     ]
    }
   ],
   "source": [
    "cur_dir = Path().resolve() # this should provide you with the folder in which this notebook is placed\n",
    "path_to_file = Path.joinpath(cur_dir, 'Lab1-apple-samsung-example.txt')\n",
    "print(path_to_file)\n",
    "print('does path exist? ->', Path.exists(path_to_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the output from the code cell above states that **does path exist? -> False**, please check that the file **Lab1-apple-samsung-example.txt** is in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of characters 1139\n"
     ]
    }
   ],
   "source": [
    "with open(path_to_file) as infile:\n",
    "    text = infile.read()\n",
    "\n",
    "print('number of characters', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [total points: 4] Exercise 1: NLTK\n",
    "In this exercise, we use NLTK to apply **Part-of-speech (POS) tagging**, **Named Entity Recognition (NER)**, and **Constituency parsing**. The following code snippet already performs sentence splitting and tokenization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_nltk = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_per_sentence = []\n",
    "for sentence_nltk in sentences_nltk:\n",
    "    sent_tokens = word_tokenize(sentence_nltk)\n",
    "    tokens_per_sentence.append(sent_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use lists to keep track of the output of the NLP tasks. We can hence inspect the output for each task using the index of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE The six phones and tablets affected are the Galaxy S III, running the new Jelly Bean system, the Galaxy Tab 8.9 Wifi tablet, the Galaxy Tab 2 10.1, Galaxy Rugby Pro and Galaxy S III mini.\n",
      "TOKENS ['The', 'six', 'phones', 'and', 'tablets', 'affected', 'are', 'the', 'Galaxy', 'S', 'III', ',', 'running', 'the', 'new', 'Jelly', 'Bean', 'system', ',', 'the', 'Galaxy', 'Tab', '8.9', 'Wifi', 'tablet', ',', 'the', 'Galaxy', 'Tab', '2', '10.1', ',', 'Galaxy', 'Rugby', 'Pro', 'and', 'Galaxy', 'S', 'III', 'mini', '.']\n"
     ]
    }
   ],
   "source": [
    "sent_id = 1\n",
    "print('SENTENCE', sentences_nltk[sent_id])\n",
    "print('TOKENS', tokens_per_sentence[sent_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [point: 1] Exercise 1a: Part-of-speech (POS) tagging\n",
    "Use `nltk.pos_tag` to perform part-of-speech tagging on each sentence.\n",
    "\n",
    "Use `print` to **show** the output in the notebook (and hence also in the exported PDF!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('https', 'NN'), (':', ':'), ('//www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html', 'JJ'), ('Documents', 'NNS'), ('filed', 'VBN'), ('to', 'TO'), ('the', 'DT'), ('San', 'NNP'), ('Jose', 'NNP'), ('federal', 'JJ'), ('court', 'NN'), ('in', 'IN'), ('California', 'NNP'), ('on', 'IN'), ('November', 'NNP'), ('23', 'CD'), ('list', 'NN'), ('six', 'CD'), ('Samsung', 'NNP'), ('products', 'NNS'), ('running', 'VBG'), ('the', 'DT'), ('``', '``'), ('Jelly', 'RB'), ('Bean', 'NNP'), (\"''\", \"''\"), ('and', 'CC'), ('``', '``'), ('Ice', 'NNP'), ('Cream', 'NNP'), ('Sandwich', 'NNP'), (\"''\", \"''\"), ('operating', 'VBG'), ('systems', 'NNS'), (',', ','), ('which', 'WDT'), ('Apple', 'NNP'), ('claims', 'VBZ'), ('infringe', 'VB'), ('its', 'PRP$'), ('patents', 'NNS'), ('.', '.')]\n",
      "\n",
      "[('The', 'DT'), ('six', 'CD'), ('phones', 'NNS'), ('and', 'CC'), ('tablets', 'NNS'), ('affected', 'VBN'), ('are', 'VBP'), ('the', 'DT'), ('Galaxy', 'NNP'), ('S', 'NNP'), ('III', 'NNP'), (',', ','), ('running', 'VBG'), ('the', 'DT'), ('new', 'JJ'), ('Jelly', 'NNP'), ('Bean', 'NNP'), ('system', 'NN'), (',', ','), ('the', 'DT'), ('Galaxy', 'NNP'), ('Tab', 'NNP'), ('8.9', 'CD'), ('Wifi', 'NNP'), ('tablet', 'NN'), (',', ','), ('the', 'DT'), ('Galaxy', 'NNP'), ('Tab', 'NNP'), ('2', 'CD'), ('10.1', 'CD'), (',', ','), ('Galaxy', 'NNP'), ('Rugby', 'NNP'), ('Pro', 'NNP'), ('and', 'CC'), ('Galaxy', 'NNP'), ('S', 'NNP'), ('III', 'NNP'), ('mini', 'NN'), ('.', '.')]\n",
      "\n",
      "[('Apple', 'NNP'), ('stated', 'VBD'), ('it', 'PRP'), ('had', 'VBD'), ('“', 'NNP'), ('acted', 'VBD'), ('quickly', 'RB'), ('and', 'CC'), ('diligently', 'RB'), (\"''\", \"''\"), ('in', 'IN'), ('order', 'NN'), ('to', 'TO'), ('``', '``'), ('determine', 'VB'), ('that', 'IN'), ('these', 'DT'), ('newly', 'RB'), ('released', 'VBN'), ('products', 'NNS'), ('do', 'VBP'), ('infringe', 'VB'), ('many', 'JJ'), ('of', 'IN'), ('the', 'DT'), ('same', 'JJ'), ('claims', 'NNS'), ('already', 'RB'), ('asserted', 'VBN'), ('by', 'IN'), ('Apple', 'NNP'), ('.', '.'), (\"''\", \"''\")]\n",
      "\n",
      "[('In', 'IN'), ('August', 'NNP'), (',', ','), ('Samsung', 'NNP'), ('lost', 'VBD'), ('a', 'DT'), ('US', 'NNP'), ('patent', 'NN'), ('case', 'NN'), ('to', 'TO'), ('Apple', 'NNP'), ('and', 'CC'), ('was', 'VBD'), ('ordered', 'VBN'), ('to', 'TO'), ('pay', 'VB'), ('its', 'PRP$'), ('rival', 'JJ'), ('$', '$'), ('1.05bn', 'CD'), ('(', '('), ('£0.66bn', 'NN'), (')', ')'), ('in', 'IN'), ('damages', 'NNS'), ('for', 'IN'), ('copying', 'VBG'), ('features', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('iPad', 'NN'), ('and', 'CC'), ('iPhone', 'NN'), ('in', 'IN'), ('its', 'PRP$'), ('Galaxy', 'NNP'), ('range', 'NN'), ('of', 'IN'), ('devices', 'NNS'), ('.', '.')]\n",
      "\n",
      "[('Samsung', 'NNP'), (',', ','), ('which', 'WDT'), ('is', 'VBZ'), ('the', 'DT'), ('world', 'NN'), (\"'s\", 'POS'), ('top', 'JJ'), ('mobile', 'NN'), ('phone', 'NN'), ('maker', 'NN'), (',', ','), ('is', 'VBZ'), ('appealing', 'VBG'), ('the', 'DT'), ('ruling', 'NN'), ('.', '.')]\n",
      "\n",
      "[('A', 'DT'), ('similar', 'JJ'), ('case', 'NN'), ('in', 'IN'), ('the', 'DT'), ('UK', 'NNP'), ('found', 'VBD'), ('in', 'IN'), ('Samsung', 'NNP'), (\"'s\", 'POS'), ('favour', 'NN'), ('and', 'CC'), ('ordered', 'VBD'), ('Apple', 'NNP'), ('to', 'TO'), ('publish', 'VB'), ('an', 'DT'), ('apology', 'NN'), ('making', 'VBG'), ('clear', 'JJ'), ('that', 'IN'), ('the', 'DT'), ('South', 'JJ'), ('Korean', 'JJ'), ('firm', 'NN'), ('had', 'VBD'), ('not', 'RB'), ('copied', 'VBN'), ('its', 'PRP$'), ('iPad', 'NN'), ('when', 'WRB'), ('designing', 'VBG'), ('its', 'PRP$'), ('own', 'JJ'), ('devices', 'NNS'), ('.', '.')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pos_tags_per_sentence = []\n",
    "for tokens in tokens_per_sentence:\n",
    "    pos_tagged = nltk.pos_tag(tokens)\n",
    "    pos_tags_per_sentence.append(pos_tagged)\n",
    "\n",
    "    print(pos_tagged)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pos_tags_per_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [point: 1] Exercise 1b: Named Entity Recognition (NER)\n",
    "Use `nltk.chunk.ne_chunk` to perform Named Entity Recognition (NER) on each sentence.\n",
    "\n",
    "Use `print` to **show** the output in the notebook (and hence also in the exported PDF!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.chunk import ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  https/NN\n",
      "  :/:\n",
      "  //www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html/JJ\n",
      "  Documents/NNS\n",
      "  filed/VBN\n",
      "  to/TO\n",
      "  the/DT\n",
      "  (ORGANIZATION San/NNP Jose/NNP)\n",
      "  federal/JJ\n",
      "  court/NN\n",
      "  in/IN\n",
      "  (GPE California/NNP)\n",
      "  on/IN\n",
      "  November/NNP\n",
      "  23/CD\n",
      "  list/NN\n",
      "  six/CD\n",
      "  (ORGANIZATION Samsung/NNP)\n",
      "  products/NNS\n",
      "  running/VBG\n",
      "  the/DT\n",
      "  ``/``\n",
      "  Jelly/RB\n",
      "  (GPE Bean/NNP)\n",
      "  ''/''\n",
      "  and/CC\n",
      "  ``/``\n",
      "  Ice/NNP\n",
      "  Cream/NNP\n",
      "  Sandwich/NNP\n",
      "  ''/''\n",
      "  operating/VBG\n",
      "  systems/NNS\n",
      "  ,/,\n",
      "  which/WDT\n",
      "  (PERSON Apple/NNP)\n",
      "  claims/VBZ\n",
      "  infringe/VB\n",
      "  its/PRP$\n",
      "  patents/NNS\n",
      "  ./.)\n",
      "\n",
      "(S\n",
      "  The/DT\n",
      "  six/CD\n",
      "  phones/NNS\n",
      "  and/CC\n",
      "  tablets/NNS\n",
      "  affected/VBN\n",
      "  are/VBP\n",
      "  the/DT\n",
      "  (ORGANIZATION Galaxy/NNP)\n",
      "  S/NNP\n",
      "  III/NNP\n",
      "  ,/,\n",
      "  running/VBG\n",
      "  the/DT\n",
      "  new/JJ\n",
      "  (PERSON Jelly/NNP Bean/NNP)\n",
      "  system/NN\n",
      "  ,/,\n",
      "  the/DT\n",
      "  (ORGANIZATION Galaxy/NNP)\n",
      "  Tab/NNP\n",
      "  8.9/CD\n",
      "  Wifi/NNP\n",
      "  tablet/NN\n",
      "  ,/,\n",
      "  the/DT\n",
      "  (ORGANIZATION Galaxy/NNP)\n",
      "  Tab/NNP\n",
      "  2/CD\n",
      "  10.1/CD\n",
      "  ,/,\n",
      "  (PERSON Galaxy/NNP Rugby/NNP Pro/NNP)\n",
      "  and/CC\n",
      "  (PERSON Galaxy/NNP S/NNP)\n",
      "  III/NNP\n",
      "  mini/NN\n",
      "  ./.)\n",
      "\n",
      "(S\n",
      "  (PERSON Apple/NNP)\n",
      "  stated/VBD\n",
      "  it/PRP\n",
      "  had/VBD\n",
      "  “/NNP\n",
      "  acted/VBD\n",
      "  quickly/RB\n",
      "  and/CC\n",
      "  diligently/RB\n",
      "  ''/''\n",
      "  in/IN\n",
      "  order/NN\n",
      "  to/TO\n",
      "  ``/``\n",
      "  determine/VB\n",
      "  that/IN\n",
      "  these/DT\n",
      "  newly/RB\n",
      "  released/VBN\n",
      "  products/NNS\n",
      "  do/VBP\n",
      "  infringe/VB\n",
      "  many/JJ\n",
      "  of/IN\n",
      "  the/DT\n",
      "  same/JJ\n",
      "  claims/NNS\n",
      "  already/RB\n",
      "  asserted/VBN\n",
      "  by/IN\n",
      "  (PERSON Apple/NNP)\n",
      "  ./.\n",
      "  ''/'')\n",
      "\n",
      "(S\n",
      "  In/IN\n",
      "  (GPE August/NNP)\n",
      "  ,/,\n",
      "  (PERSON Samsung/NNP)\n",
      "  lost/VBD\n",
      "  a/DT\n",
      "  (GSP US/NNP)\n",
      "  patent/NN\n",
      "  case/NN\n",
      "  to/TO\n",
      "  (GPE Apple/NNP)\n",
      "  and/CC\n",
      "  was/VBD\n",
      "  ordered/VBN\n",
      "  to/TO\n",
      "  pay/VB\n",
      "  its/PRP$\n",
      "  rival/JJ\n",
      "  $/$\n",
      "  1.05bn/CD\n",
      "  (/(\n",
      "  £0.66bn/NN\n",
      "  )/)\n",
      "  in/IN\n",
      "  damages/NNS\n",
      "  for/IN\n",
      "  copying/VBG\n",
      "  features/NNS\n",
      "  of/IN\n",
      "  the/DT\n",
      "  (ORGANIZATION iPad/NN)\n",
      "  and/CC\n",
      "  (ORGANIZATION iPhone/NN)\n",
      "  in/IN\n",
      "  its/PRP$\n",
      "  (GPE Galaxy/NNP)\n",
      "  range/NN\n",
      "  of/IN\n",
      "  devices/NNS\n",
      "  ./.)\n",
      "\n",
      "(S\n",
      "  (GPE Samsung/NNP)\n",
      "  ,/,\n",
      "  which/WDT\n",
      "  is/VBZ\n",
      "  the/DT\n",
      "  world/NN\n",
      "  's/POS\n",
      "  top/JJ\n",
      "  mobile/NN\n",
      "  phone/NN\n",
      "  maker/NN\n",
      "  ,/,\n",
      "  is/VBZ\n",
      "  appealing/VBG\n",
      "  the/DT\n",
      "  ruling/NN\n",
      "  ./.)\n",
      "\n",
      "(S\n",
      "  A/DT\n",
      "  similar/JJ\n",
      "  case/NN\n",
      "  in/IN\n",
      "  the/DT\n",
      "  (ORGANIZATION UK/NNP)\n",
      "  found/VBD\n",
      "  in/IN\n",
      "  (GPE Samsung/NNP)\n",
      "  's/POS\n",
      "  favour/NN\n",
      "  and/CC\n",
      "  ordered/VBD\n",
      "  (PERSON Apple/NNP)\n",
      "  to/TO\n",
      "  publish/VB\n",
      "  an/DT\n",
      "  apology/NN\n",
      "  making/VBG\n",
      "  clear/JJ\n",
      "  that/IN\n",
      "  the/DT\n",
      "  (LOCATION South/JJ Korean/JJ)\n",
      "  firm/NN\n",
      "  had/VBD\n",
      "  not/RB\n",
      "  copied/VBN\n",
      "  its/PRP$\n",
      "  iPad/NN\n",
      "  when/WRB\n",
      "  designing/VBG\n",
      "  its/PRP$\n",
      "  own/JJ\n",
      "  devices/NNS\n",
      "  ./.)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ner_tags_per_sentence = []\n",
    "\n",
    "for pos_tagged in pos_tags_per_sentence:\n",
    "    ne_chunked = ne_chunk(pos_tagged)\n",
    "    ner_tags_per_sentence.append(ne_chunked)\n",
    "\n",
    "    print(ne_chunked)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ner_tags_per_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [points: 2] Exercise 1c: Constituency parsing\n",
    "Use the `nltk.RegexpParser` to perform constituency parsing on each sentence.\n",
    "\n",
    "Use `print` to **show** the output in the notebook (and hence also in the exported PDF!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituent_parser = nltk.RegexpParser('''\n",
    "NP: {<DT>? <JJ>* <NN>*} # NP\n",
    "P: {<IN>}           # Preposition\n",
    "V: {<V.*>}          # Verb\n",
    "PP: {<P> <NP>}      # PP -> P NP\n",
    "VP: {<V> <NP|PP>*}  # VP -> V (NP|PP)*''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP https/NN)\n",
      "  :/:\n",
      "  (NP\n",
      "    //www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html/JJ)\n",
      "  Documents/NNS\n",
      "  (VP (V filed/VBN))\n",
      "  to/TO\n",
      "  (NP the/DT)\n",
      "  San/NNP\n",
      "  Jose/NNP\n",
      "  (NP federal/JJ court/NN)\n",
      "  (P in/IN)\n",
      "  California/NNP\n",
      "  (P on/IN)\n",
      "  November/NNP\n",
      "  23/CD\n",
      "  (NP list/NN)\n",
      "  six/CD\n",
      "  Samsung/NNP\n",
      "  products/NNS\n",
      "  (VP (V running/VBG) (NP the/DT))\n",
      "  ``/``\n",
      "  Jelly/RB\n",
      "  Bean/NNP\n",
      "  ''/''\n",
      "  and/CC\n",
      "  ``/``\n",
      "  Ice/NNP\n",
      "  Cream/NNP\n",
      "  Sandwich/NNP\n",
      "  ''/''\n",
      "  (VP (V operating/VBG))\n",
      "  systems/NNS\n",
      "  ,/,\n",
      "  which/WDT\n",
      "  Apple/NNP\n",
      "  (VP (V claims/VBZ))\n",
      "  (VP (V infringe/VB))\n",
      "  its/PRP$\n",
      "  patents/NNS\n",
      "  ./.)\n",
      "\n",
      "(S\n",
      "  (NP The/DT)\n",
      "  six/CD\n",
      "  phones/NNS\n",
      "  and/CC\n",
      "  tablets/NNS\n",
      "  (VP (V affected/VBN))\n",
      "  (VP (V are/VBP) (NP the/DT))\n",
      "  Galaxy/NNP\n",
      "  S/NNP\n",
      "  III/NNP\n",
      "  ,/,\n",
      "  (VP (V running/VBG) (NP the/DT new/JJ))\n",
      "  Jelly/NNP\n",
      "  Bean/NNP\n",
      "  (NP system/NN)\n",
      "  ,/,\n",
      "  (NP the/DT)\n",
      "  Galaxy/NNP\n",
      "  Tab/NNP\n",
      "  8.9/CD\n",
      "  Wifi/NNP\n",
      "  (NP tablet/NN)\n",
      "  ,/,\n",
      "  (NP the/DT)\n",
      "  Galaxy/NNP\n",
      "  Tab/NNP\n",
      "  2/CD\n",
      "  10.1/CD\n",
      "  ,/,\n",
      "  Galaxy/NNP\n",
      "  Rugby/NNP\n",
      "  Pro/NNP\n",
      "  and/CC\n",
      "  Galaxy/NNP\n",
      "  S/NNP\n",
      "  III/NNP\n",
      "  (NP mini/NN)\n",
      "  ./.)\n",
      "\n",
      "(S\n",
      "  Apple/NNP\n",
      "  (VP (V stated/VBD))\n",
      "  it/PRP\n",
      "  (VP (V had/VBD))\n",
      "  “/NNP\n",
      "  (VP (V acted/VBD))\n",
      "  quickly/RB\n",
      "  and/CC\n",
      "  diligently/RB\n",
      "  ''/''\n",
      "  (PP (P in/IN) (NP order/NN))\n",
      "  to/TO\n",
      "  ``/``\n",
      "  (VP (V determine/VB) (PP (P that/IN) (NP these/DT)))\n",
      "  newly/RB\n",
      "  (VP (V released/VBN))\n",
      "  products/NNS\n",
      "  (VP (V do/VBP))\n",
      "  (VP\n",
      "    (V infringe/VB)\n",
      "    (NP many/JJ)\n",
      "    (PP (P of/IN) (NP the/DT same/JJ)))\n",
      "  claims/NNS\n",
      "  already/RB\n",
      "  (VP (V asserted/VBN))\n",
      "  (P by/IN)\n",
      "  Apple/NNP\n",
      "  ./.\n",
      "  ''/'')\n",
      "\n",
      "(S\n",
      "  (P In/IN)\n",
      "  August/NNP\n",
      "  ,/,\n",
      "  Samsung/NNP\n",
      "  (VP (V lost/VBD) (NP a/DT))\n",
      "  US/NNP\n",
      "  (NP patent/NN case/NN)\n",
      "  to/TO\n",
      "  Apple/NNP\n",
      "  and/CC\n",
      "  (VP (V was/VBD))\n",
      "  (VP (V ordered/VBN))\n",
      "  to/TO\n",
      "  (VP (V pay/VB))\n",
      "  its/PRP$\n",
      "  (NP rival/JJ)\n",
      "  $/$\n",
      "  1.05bn/CD\n",
      "  (/(\n",
      "  (NP £0.66bn/NN)\n",
      "  )/)\n",
      "  (P in/IN)\n",
      "  damages/NNS\n",
      "  (P for/IN)\n",
      "  (VP (V copying/VBG))\n",
      "  features/NNS\n",
      "  (PP (P of/IN) (NP the/DT iPad/NN))\n",
      "  and/CC\n",
      "  (NP iPhone/NN)\n",
      "  (P in/IN)\n",
      "  its/PRP$\n",
      "  Galaxy/NNP\n",
      "  (NP range/NN)\n",
      "  (P of/IN)\n",
      "  devices/NNS\n",
      "  ./.)\n",
      "\n",
      "(S\n",
      "  Samsung/NNP\n",
      "  ,/,\n",
      "  which/WDT\n",
      "  (VP (V is/VBZ) (NP the/DT world/NN))\n",
      "  's/POS\n",
      "  (NP top/JJ mobile/NN phone/NN maker/NN)\n",
      "  ,/,\n",
      "  (VP (V is/VBZ))\n",
      "  (VP (V appealing/VBG) (NP the/DT ruling/NN))\n",
      "  ./.)\n",
      "\n",
      "(S\n",
      "  (NP A/DT similar/JJ case/NN)\n",
      "  (PP (P in/IN) (NP the/DT))\n",
      "  UK/NNP\n",
      "  (VP (V found/VBD))\n",
      "  (P in/IN)\n",
      "  Samsung/NNP\n",
      "  's/POS\n",
      "  (NP favour/NN)\n",
      "  and/CC\n",
      "  (VP (V ordered/VBD))\n",
      "  Apple/NNP\n",
      "  to/TO\n",
      "  (VP (V publish/VB) (NP an/DT apology/NN))\n",
      "  (VP\n",
      "    (V making/VBG)\n",
      "    (NP clear/JJ)\n",
      "    (PP (P that/IN) (NP the/DT South/JJ Korean/JJ firm/NN)))\n",
      "  (VP (V had/VBD))\n",
      "  not/RB\n",
      "  (VP (V copied/VBN))\n",
      "  its/PRP$\n",
      "  (NP iPad/NN)\n",
      "  when/WRB\n",
      "  (VP (V designing/VBG))\n",
      "  its/PRP$\n",
      "  (NP own/JJ)\n",
      "  devices/NNS\n",
      "  ./.)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "constituency_output_per_sentence = []\n",
    "\n",
    "for pos_tagged in pos_tags_per_sentence:\n",
    "    const_parsed = constituent_parser.parse(pos_tagged)\n",
    "    constituency_output_per_sentence.append(const_parsed)\n",
    "\n",
    "    print(const_parsed)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(constituency_output_per_sentence)\n",
    "# constituency_output_per_sentence[1].draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment the RegexpParser so that it also detects Named Entity Phrases (NEP), e.g., that it detects *Galaxy S III* and *Ice Cream Sandwich*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituent_parser_v2 = nltk.RegexpParser('''\n",
    "NP: {<DT>? <JJ>* <NN>*} # NP\n",
    "P: {<IN>}           # Preposition\n",
    "V: {<V.*>}          # Verb\n",
    "PP: {<P> <NP>}      # PP -> P NP\n",
    "VP: {<V> <NP|PP>*}  # VP -> V (NP|PP)*\n",
    "NEP: {<NNP>+}       # Named Entities''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP https/NN)\n",
      "  :/:\n",
      "  (NP\n",
      "    //www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html/JJ)\n",
      "  Documents/NNS\n",
      "  (VP (V filed/VBN))\n",
      "  to/TO\n",
      "  (NP the/DT)\n",
      "  (NEP San/NNP Jose/NNP)\n",
      "  (NP federal/JJ court/NN)\n",
      "  (P in/IN)\n",
      "  (NEP California/NNP)\n",
      "  (P on/IN)\n",
      "  (NEP November/NNP)\n",
      "  23/CD\n",
      "  (NP list/NN)\n",
      "  six/CD\n",
      "  (NEP Samsung/NNP)\n",
      "  products/NNS\n",
      "  (VP (V running/VBG) (NP the/DT))\n",
      "  ``/``\n",
      "  Jelly/RB\n",
      "  (NEP Bean/NNP)\n",
      "  ''/''\n",
      "  and/CC\n",
      "  ``/``\n",
      "  (NEP Ice/NNP Cream/NNP Sandwich/NNP)\n",
      "  ''/''\n",
      "  (VP (V operating/VBG))\n",
      "  systems/NNS\n",
      "  ,/,\n",
      "  which/WDT\n",
      "  (NEP Apple/NNP)\n",
      "  (VP (V claims/VBZ))\n",
      "  (VP (V infringe/VB))\n",
      "  its/PRP$\n",
      "  patents/NNS\n",
      "  ./.)\n",
      "\n",
      "(S\n",
      "  (NP The/DT)\n",
      "  six/CD\n",
      "  phones/NNS\n",
      "  and/CC\n",
      "  tablets/NNS\n",
      "  (VP (V affected/VBN))\n",
      "  (VP (V are/VBP) (NP the/DT))\n",
      "  (NEP Galaxy/NNP S/NNP III/NNP)\n",
      "  ,/,\n",
      "  (VP (V running/VBG) (NP the/DT new/JJ))\n",
      "  (NEP Jelly/NNP Bean/NNP)\n",
      "  (NP system/NN)\n",
      "  ,/,\n",
      "  (NP the/DT)\n",
      "  (NEP Galaxy/NNP Tab/NNP)\n",
      "  8.9/CD\n",
      "  (NEP Wifi/NNP)\n",
      "  (NP tablet/NN)\n",
      "  ,/,\n",
      "  (NP the/DT)\n",
      "  (NEP Galaxy/NNP Tab/NNP)\n",
      "  2/CD\n",
      "  10.1/CD\n",
      "  ,/,\n",
      "  (NEP Galaxy/NNP Rugby/NNP Pro/NNP)\n",
      "  and/CC\n",
      "  (NEP Galaxy/NNP S/NNP III/NNP)\n",
      "  (NP mini/NN)\n",
      "  ./.)\n",
      "\n",
      "(S\n",
      "  (NEP Apple/NNP)\n",
      "  (VP (V stated/VBD))\n",
      "  it/PRP\n",
      "  (VP (V had/VBD))\n",
      "  (NEP “/NNP)\n",
      "  (VP (V acted/VBD))\n",
      "  quickly/RB\n",
      "  and/CC\n",
      "  diligently/RB\n",
      "  ''/''\n",
      "  (PP (P in/IN) (NP order/NN))\n",
      "  to/TO\n",
      "  ``/``\n",
      "  (VP (V determine/VB) (PP (P that/IN) (NP these/DT)))\n",
      "  newly/RB\n",
      "  (VP (V released/VBN))\n",
      "  products/NNS\n",
      "  (VP (V do/VBP))\n",
      "  (VP\n",
      "    (V infringe/VB)\n",
      "    (NP many/JJ)\n",
      "    (PP (P of/IN) (NP the/DT same/JJ)))\n",
      "  claims/NNS\n",
      "  already/RB\n",
      "  (VP (V asserted/VBN))\n",
      "  (P by/IN)\n",
      "  (NEP Apple/NNP)\n",
      "  ./.\n",
      "  ''/'')\n",
      "\n",
      "(S\n",
      "  (P In/IN)\n",
      "  (NEP August/NNP)\n",
      "  ,/,\n",
      "  (NEP Samsung/NNP)\n",
      "  (VP (V lost/VBD) (NP a/DT))\n",
      "  (NEP US/NNP)\n",
      "  (NP patent/NN case/NN)\n",
      "  to/TO\n",
      "  (NEP Apple/NNP)\n",
      "  and/CC\n",
      "  (VP (V was/VBD))\n",
      "  (VP (V ordered/VBN))\n",
      "  to/TO\n",
      "  (VP (V pay/VB))\n",
      "  its/PRP$\n",
      "  (NP rival/JJ)\n",
      "  $/$\n",
      "  1.05bn/CD\n",
      "  (/(\n",
      "  (NP £0.66bn/NN)\n",
      "  )/)\n",
      "  (P in/IN)\n",
      "  damages/NNS\n",
      "  (P for/IN)\n",
      "  (VP (V copying/VBG))\n",
      "  features/NNS\n",
      "  (PP (P of/IN) (NP the/DT iPad/NN))\n",
      "  and/CC\n",
      "  (NP iPhone/NN)\n",
      "  (P in/IN)\n",
      "  its/PRP$\n",
      "  (NEP Galaxy/NNP)\n",
      "  (NP range/NN)\n",
      "  (P of/IN)\n",
      "  devices/NNS\n",
      "  ./.)\n",
      "\n",
      "(S\n",
      "  (NEP Samsung/NNP)\n",
      "  ,/,\n",
      "  which/WDT\n",
      "  (VP (V is/VBZ) (NP the/DT world/NN))\n",
      "  's/POS\n",
      "  (NP top/JJ mobile/NN phone/NN maker/NN)\n",
      "  ,/,\n",
      "  (VP (V is/VBZ))\n",
      "  (VP (V appealing/VBG) (NP the/DT ruling/NN))\n",
      "  ./.)\n",
      "\n",
      "(S\n",
      "  (NP A/DT similar/JJ case/NN)\n",
      "  (PP (P in/IN) (NP the/DT))\n",
      "  (NEP UK/NNP)\n",
      "  (VP (V found/VBD))\n",
      "  (P in/IN)\n",
      "  (NEP Samsung/NNP)\n",
      "  's/POS\n",
      "  (NP favour/NN)\n",
      "  and/CC\n",
      "  (VP (V ordered/VBD))\n",
      "  (NEP Apple/NNP)\n",
      "  to/TO\n",
      "  (VP (V publish/VB) (NP an/DT apology/NN))\n",
      "  (VP\n",
      "    (V making/VBG)\n",
      "    (NP clear/JJ)\n",
      "    (PP (P that/IN) (NP the/DT South/JJ Korean/JJ firm/NN)))\n",
      "  (VP (V had/VBD))\n",
      "  not/RB\n",
      "  (VP (V copied/VBN))\n",
      "  its/PRP$\n",
      "  (NP iPad/NN)\n",
      "  when/WRB\n",
      "  (VP (V designing/VBG))\n",
      "  its/PRP$\n",
      "  (NP own/JJ)\n",
      "  devices/NNS\n",
      "  ./.)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "constituency_v2_output_per_sentence = []\n",
    "\n",
    "for pos_tagged in pos_tags_per_sentence:\n",
    "    const_parsed_v2 = constituent_parser_v2.parse(pos_tagged)\n",
    "    constituency_v2_output_per_sentence.append(const_parsed_v2)\n",
    "\n",
    "    print(const_parsed_v2)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(constituency_v2_output_per_sentence)\n",
    "# constituency_v2_output_per_sentence[0].draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [total points: 1] Exercise 2: spaCy\n",
    "Use Spacy to process the same text as you analyzed with NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text) # insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "small tip: You can use **sents = list(doc.sents)** to be able to use the index to access a sentence like **sents[2]** for the third sentence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [total points: 7] Exercise 3: Comparison NLTK and spaCy\n",
    "We will now compare the output of NLTK and spaCy, i.e., in what do they differ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [points: 3] Exercise 3a: Part of speech tagging\n",
    "Compare the output from NLTK and spaCy regarding part of speech tagging.\n",
    "\n",
    "* To compare, you probably would like to compare sentence per sentence. Describe if the sentence splitting is different for NLTK than for spaCy. If not, where do they differ?\n",
    "* After checking the sentence splitting, select a sentence for which you expect interesting results and perhaps differences. Motivate your choice.\n",
    "* Compare the output in `token.tag` from spaCy to the part of speech tagging from NLTK for each token in your selected sentence. Are there any differences? This is not a trick question; it is possible that there are no differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Splitting Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NLTK:\n",
      "https://www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html\n",
      "\n",
      "Documents filed to the San Jose federal court in California on November 23 list six Samsung products running the \"Jelly Bean\" and \"Ice Cream Sandwich\" operating systems, which Apple claims infringe its patents.\n",
      "\n",
      "Spacy:\n",
      "https://www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html\n",
      "\n",
      "Documents filed to the San Jose federal court in California on November 23 list six Samsung products running the \"Jelly Bean\" and \"Ice Cream Sandwich\" operating systems, which Apple claims infringe its patents.\n",
      "---------------------------\n",
      "NLTK:\n",
      "The six phones and tablets affected are the Galaxy S III, running the new Jelly Bean system, the Galaxy Tab 8.9 Wifi tablet, the Galaxy Tab 2 10.1, Galaxy Rugby Pro and Galaxy S III mini.\n",
      "\n",
      "Spacy:\n",
      "The six phones and tablets affected are the Galaxy S III, running the new Jelly Bean system, the Galaxy Tab 8.9 Wifi tablet, the Galaxy Tab 2 10.1, Galaxy Rugby Pro and Galaxy S III mini.\n",
      "---------------------------\n",
      "NLTK:\n",
      "Apple stated it had “acted quickly and diligently\" in order to \"determine that these newly released products do infringe many of the same claims already asserted by Apple.\"\n",
      "\n",
      "Spacy:\n",
      "\n",
      "Apple stated it had “acted quickly and diligently\" in order to \"determine that these newly released products do infringe many of the same claims already asserted by Apple.\"\n",
      "---------------------------\n",
      "NLTK:\n",
      "In August, Samsung lost a US patent case to Apple and was ordered to pay its rival $1.05bn (£0.66bn) in damages for copying features of the iPad and iPhone in its Galaxy range of devices.\n",
      "\n",
      "Spacy:\n",
      "\n",
      "In August, Samsung lost a US patent case to Apple and was ordered to pay its rival $1.05bn (£0.66bn) in damages for copying features of the iPad and iPhone in its Galaxy range of devices.\n",
      "---------------------------\n",
      "NLTK:\n",
      "Samsung, which is the world's top mobile phone maker, is appealing the ruling.\n",
      "\n",
      "Spacy:\n",
      "Samsung, which is the world's top mobile phone maker, is appealing the ruling.\n",
      "---------------------------\n",
      "NLTK:\n",
      "A similar case in the UK found in Samsung's favour and ordered Apple to publish an apology making clear that the South Korean firm had not copied its iPad when designing its own devices.\n",
      "\n",
      "Spacy:\n",
      "\n",
      "A similar case in the UK found in Samsung's favour and ordered Apple to publish an apology making clear that the South Korean firm had not copied its iPad when designing its own devices.\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "nltk_list, spacy_list = list(sentences_nltk), list(doc.sents)\n",
    "print(spacy_list[1].text == '\\n')\n",
    "del spacy_list[1]\n",
    "nltk_iter, spacy_iter = iter(nltk_list), iter(spacy_list)\n",
    "\n",
    "for _ in range(max(len(nltk_list), len(spacy_list))):\n",
    "    print('NLTK:')\n",
    "    print(next(nltk_iter, 'N/A'))\n",
    "    print()\n",
    "    print('Spacy:')\n",
    "    print(next(spacy_iter, 'N/A'))\n",
    "    print('---------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "For some reason SpaCy splits \"\\n\" as a sentence (first index). Aside from that the sentence splitting is identical. I removed that problem to be able to see the comparison easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS tagging comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_spacy = doc.sents\n",
    "pos_tags_per_sentence_spacy = []\n",
    "\n",
    "for idx, sentence in enumerate(sentences_spacy):\n",
    "    pos_tags_per_sentence_spacy.append([])\n",
    "\n",
    "    for token in sentence:\n",
    "        pos_tags_per_sentence_spacy[idx].append([token.text, token.tag_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html NNP\n",
      "\n",
      "\n",
      " _SP\n",
      "Documents NNS\n",
      "filed VBD\n",
      "to IN\n",
      "the DT\n",
      "San NNP\n",
      "Jose NNP\n",
      "federal JJ\n",
      "court NN\n",
      "in IN\n",
      "California NNP\n",
      "on IN\n",
      "November NNP\n",
      "23 CD\n",
      "list NN\n",
      "six CD\n",
      "Samsung NNP\n",
      "products NNS\n",
      "running VBG\n",
      "the DT\n",
      "\" ``\n",
      "Jelly NNP\n",
      "Bean NNP\n",
      "\" ''\n",
      "and CC\n",
      "\" ``\n",
      "Ice NNP\n",
      "Cream NNP\n",
      "Sandwich NNP\n",
      "\" ''\n",
      "operating NN\n",
      "systems NNS\n",
      ", ,\n",
      "which WDT\n",
      "Apple NNP\n",
      "claims NNS\n",
      "infringe VBP\n",
      "its PRP$\n",
      "patents NNS\n",
      ". .\n",
      "https NN\n",
      ": :\n",
      "//www.telegraph.co.uk/technology/apple/9702716/Apple-Samsung-lawsuit-six-more-products-under-scrutiny.html JJ\n",
      "Documents NNS\n",
      "filed VBN\n",
      "to TO\n",
      "the DT\n",
      "San NNP\n",
      "Jose NNP\n",
      "federal JJ\n",
      "court NN\n",
      "in IN\n",
      "California NNP\n",
      "on IN\n",
      "November NNP\n",
      "23 CD\n",
      "list NN\n",
      "six CD\n",
      "Samsung NNP\n",
      "products NNS\n",
      "running VBG\n",
      "the DT\n",
      "`` ``\n",
      "Jelly RB\n",
      "Bean NNP\n",
      "'' ''\n",
      "and CC\n",
      "`` ``\n",
      "Ice NNP\n",
      "Cream NNP\n",
      "Sandwich NNP\n",
      "'' ''\n",
      "operating VBG\n",
      "systems NNS\n",
      ", ,\n",
      "which WDT\n",
      "Apple NNP\n",
      "claims VBZ\n",
      "infringe VB\n",
      "its PRP$\n",
      "patents NNS\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "for pos_tag in pos_tags_per_sentence_spacy[0]:\n",
    "    print(pos_tag[0], pos_tag[1])\n",
    "\n",
    "print(\"--------------------\")\n",
    "\n",
    "for pos_tag in pos_tags_per_sentence[0]:\n",
    "    print(pos_tag[0], pos_tag[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "I chose the first sentence because it contains a URL and in all other respects the sentences are similar (contain complex sentence structures and named entities)\n",
    "\n",
    "The differences between Spacy and NLTK pos tagging are the following:\n",
    "\n",
    "Spacy:\n",
    "- Tags the whole URL as NNP\n",
    "- Tags \"filed\" as past tense\n",
    "- Correctly tags \"Jelly\" and \"Bean\" as NNP (proper noun)\n",
    "- Correctly (I think) tags \"operating\" as a type of noun (because the term is \"operating systems\")\n",
    "- Incorrectly tags \"claims\" as a type of noun\n",
    "- Tags \"infringe\" as a type of conjugated verb which I think is correct maybe(?)\n",
    "\n",
    "NLTK:\n",
    "- Tags the URL in different parts\n",
    "- Tags \"filed\" as past participle\n",
    "- Incorrectly tags only \"Bean\", and not \"Jelly\", as NNP (proper noun)\n",
    "- Incorrectly (I think) tags \"operating\" as a type of noun\n",
    "- Correctly tags \"claims\" as a type of verb\n",
    "- Tags \"infringe\" as a base form verb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [points: 2] Exercise 3b: Named Entity Recognition (NER)\n",
    "* Describe differences between the output from NLTK and spaCy for Named Entity Recognition. Which one do you think performs better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ORGANIZATION San/NNP Jose/NNP)\n",
      "(GPE California/NNP)\n",
      "(ORGANIZATION Samsung/NNP)\n",
      "(GPE Bean/NNP)\n",
      "(PERSON Apple/NNP)\n",
      "\n",
      "(ORGANIZATION Galaxy/NNP)\n",
      "(PERSON Jelly/NNP Bean/NNP)\n",
      "(ORGANIZATION Galaxy/NNP)\n",
      "(ORGANIZATION Galaxy/NNP)\n",
      "(PERSON Galaxy/NNP Rugby/NNP Pro/NNP)\n",
      "(PERSON Galaxy/NNP S/NNP)\n",
      "\n",
      "(PERSON Apple/NNP)\n",
      "(PERSON Apple/NNP)\n",
      "\n",
      "(GPE August/NNP)\n",
      "(PERSON Samsung/NNP)\n",
      "(GSP US/NNP)\n",
      "(GPE Apple/NNP)\n",
      "(ORGANIZATION iPad/NN)\n",
      "(ORGANIZATION iPhone/NN)\n",
      "(GPE Galaxy/NNP)\n",
      "\n",
      "(GPE Samsung/NNP)\n",
      "\n",
      "(ORGANIZATION UK/NNP)\n",
      "(GPE Samsung/NNP)\n",
      "(PERSON Apple/NNP)\n",
      "(LOCATION South/JJ Korean/JJ)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in ner_tags_per_sentence:\n",
    "    for ner_tag in sentence:\n",
    "        if type(ner_tag) != tuple:\n",
    "            print(ner_tag)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPE San Jose\n",
      "GPE California\n",
      "DATE November 23\n",
      "CARDINAL six\n",
      "ORG Samsung\n",
      "WORK_OF_ART Jelly Bean\n",
      "ORG Apple\n",
      "\n",
      "\n",
      "CARDINAL six\n",
      "GPE the Galaxy S III\n",
      "ORG Jelly Bean\n",
      "ORG the Galaxy Tab 2 10.1\n",
      "\n",
      "ORG Apple\n",
      "\n",
      "DATE August\n",
      "ORG Samsung\n",
      "GPE US\n",
      "ORG Apple\n",
      "MONEY 1.05bn\n",
      "ORG iPad\n",
      "ORG iPhone\n",
      "\n",
      "ORG Samsung\n",
      "\n",
      "GPE UK\n",
      "ORG Samsung\n",
      "ORG Apple\n",
      "NORP South Korean\n",
      "ORG iPad\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc.sents:\n",
    "    for ner_tag in sentence.ents:\n",
    "        print(ner_tag.label_, ner_tag.text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1:\n",
    "Spacy detects November 23, six and \"Jelly Bean\". But Spacy thinks \"Jelly Bean\" is a work of art which is wrong.\n",
    "NLTK fails to detect the first two and only detects \"Bean\", not the complete \"Jelly Bean\". Also NLTK thinks Apple is a person.\n",
    "NLTK never tags dates, times or numbers so I won't mention those in the next sentences.\n",
    "\n",
    "2:\n",
    "Spacy detects the whole name of the phone model (Galaxy Tab .... etc), whereas NLTK only detects \"Galaxy\". Both incorrectly label it in various ways, however (as e.g. organization and person). In this sentence both NLTK and Spacy detect \"Jelly Bean\", but both incorrectly label it.\n",
    "\n",
    "3:\n",
    "NLTK detects both instances of \"Apple\" but incorrectly labels it as person. Spacy only detects one \"Apple\" but correctly labels it an organization.\n",
    "\n",
    "4:\n",
    "This time NLTK detects a month (\"August\") but incorrectly labels it (thinks it's a city or something). Spacy correctly labels Samsung as an organization, NLTK labels it incorrectly. Both Spacy and NLTK get iPad and iPhone, but incorrectly label it. Only NLTK gets Galaxy, but fails to label it correctly. Spacy also detects 1.05bn as MONEY.\n",
    "\n",
    "Overall I think Spacy performs better. \n",
    "- It detects time, currency, dates, etc. which can be useful. \n",
    "- It also usually has more correct labels.\n",
    "- It sometimes misses named entities entirely when NLTK detects them (for example the last \"Galaxy\" in the fourth sentence and the second \"Apple\" in the third sentence), but it seems to have a higher rate of correct labelling when it does detect something. (So perhaps NLTK can be better depending on your needs).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [points: 2] Exercise 3c: Constituency/dependency parsing\n",
    "Choose one sentence from the text and run constituency parsing using NLTK and dependency parsing using spaCy.\n",
    "* describe briefly the difference between constituency parsing and dependency parsing\n",
    "* describe differences between the output from NLTK and spaCy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of this notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
