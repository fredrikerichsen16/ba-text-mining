{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import spacy\n",
    "import json\n",
    "import pathlib\n",
    "import time\n",
    "import gensim\n",
    "import itertools\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from helpers import preprocess_tweets, preprocess_tweet, preprocess_reddit, preprocess_reddits\n",
    "from simpletransformers.language_representation import RepresentationModel\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download links for data\n",
    "\n",
    "- Bitcoin_tweeets.csv -> https://www.kaggle.com/kaushiksuresh147/bitcoin-tweets\n",
    "- GoEmotions.csv -> https://www.kaggle.com/datasets/debarshichanda/goemotions\n",
    "- sentiment140 -> http://help.sentiment140.com/for-students/\n",
    "- GoogleNews-vectors-etc... (Word2Vec) -> Canvas(?)\n",
    "- NRC Emotion Lexicon -> https://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm\n",
    "- nrc_emotion_lexicon_dict -> Google Drive\n",
    "- BTC-USD -> https://finance.yahoo.com/quote/BTC-USD/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 90th percentile length (after removing stopwords and punctuation) was about 14 when I tested, so this is a good cutoff (99th percentile = 18)\n",
    "MAX_SENTENCE_LENGTH = 25\n",
    "TRAINING_SIZE = 60000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stanford 140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sf_train = pd.read_csv(\n",
    "#     os.path.abspath('data/sentiment140-train.csv'), \n",
    "#     encoding='ISO-8859-1', \n",
    "#     header=None, \n",
    "#     names=['polarity', 'id', 'date', 'query', 'user', 'text'],\n",
    "#     usecols=['polarity', 'text']\n",
    "# )\n",
    "\n",
    "# df_sf_test = pd.read_csv(\n",
    "#     os.path.abspath('data/sentiment140-test.csv'), \n",
    "#     encoding='ISO-8859-1', \n",
    "#     header=None, \n",
    "#     names=['polarity', 'id', 'date', 'query', 'user', 'text'],\n",
    "#     usecols=['polarity', 'text']\n",
    "# )\n",
    "\n",
    "# df_sf_train['polarity'] = df_sf_train['polarity'].replace(4, 1)\n",
    "# df_sf_test['polarity'] = df_sf_train['polarity'].replace(4, 1)\n",
    "\n",
    "# df_sf_train['text'] = df_sf_train['text'].apply(preprocess_tweet)\n",
    "# df_sf_test['text'] = df_sf_test['text'].apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sf_test.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GoEmotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_goemotion = pd.read_csv(os.path.abspath('data/GoEmotions.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211225"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_goemotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>rater_id</th>\n",
       "      <th>example_very_unclear</th>\n",
       "      <th>admiration</th>\n",
       "      <th>...</th>\n",
       "      <th>love</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>eew5j0j</td>\n",
       "      <td>Brdd9</td>\n",
       "      <td>nrl</td>\n",
       "      <td>t3_ajis4z</td>\n",
       "      <td>t1_eew18eq</td>\n",
       "      <td>1.548381e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;sexuality shouldn’t be a grouping category I...</td>\n",
       "      <td>eemcysk</td>\n",
       "      <td>TheGreen888</td>\n",
       "      <td>unpopularopinion</td>\n",
       "      <td>t3_ai4q37</td>\n",
       "      <td>t3_ai4q37</td>\n",
       "      <td>1.548084e+09</td>\n",
       "      <td>37</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You do right, if you don't care then fuck 'em!</td>\n",
       "      <td>ed2mah1</td>\n",
       "      <td>Labalool</td>\n",
       "      <td>confessions</td>\n",
       "      <td>t3_abru74</td>\n",
       "      <td>t1_ed2m7g7</td>\n",
       "      <td>1.546428e+09</td>\n",
       "      <td>37</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man I love reddit.</td>\n",
       "      <td>eeibobj</td>\n",
       "      <td>MrsRobertshaw</td>\n",
       "      <td>facepalm</td>\n",
       "      <td>t3_ahulml</td>\n",
       "      <td>t3_ahulml</td>\n",
       "      <td>1.547965e+09</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[NAME] was nowhere near them, he was by the Fa...</td>\n",
       "      <td>eda6yn6</td>\n",
       "      <td>American_Fascist713</td>\n",
       "      <td>starwarsspeculation</td>\n",
       "      <td>t3_ackt2f</td>\n",
       "      <td>t1_eda65q2</td>\n",
       "      <td>1.546669e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       id  \\\n",
       "0                                    That game hurt.  eew5j0j   \n",
       "1   >sexuality shouldn’t be a grouping category I...  eemcysk   \n",
       "2     You do right, if you don't care then fuck 'em!  ed2mah1   \n",
       "3                                 Man I love reddit.  eeibobj   \n",
       "4  [NAME] was nowhere near them, he was by the Fa...  eda6yn6   \n",
       "\n",
       "                author            subreddit    link_id   parent_id  \\\n",
       "0                Brdd9                  nrl  t3_ajis4z  t1_eew18eq   \n",
       "1          TheGreen888     unpopularopinion  t3_ai4q37   t3_ai4q37   \n",
       "2             Labalool          confessions  t3_abru74  t1_ed2m7g7   \n",
       "3        MrsRobertshaw             facepalm  t3_ahulml   t3_ahulml   \n",
       "4  American_Fascist713  starwarsspeculation  t3_ackt2f  t1_eda65q2   \n",
       "\n",
       "    created_utc  rater_id  example_very_unclear  admiration  ...  love  \\\n",
       "0  1.548381e+09         1                 False           0  ...     0   \n",
       "1  1.548084e+09        37                  True           0  ...     0   \n",
       "2  1.546428e+09        37                 False           0  ...     0   \n",
       "3  1.547965e+09        18                 False           0  ...     1   \n",
       "4  1.546669e+09         2                 False           0  ...     0   \n",
       "\n",
       "   nervousness  optimism  pride  realization  relief  remorse  sadness  \\\n",
       "0            0         0      0            0       0        0        1   \n",
       "1            0         0      0            0       0        0        0   \n",
       "2            0         0      0            0       0        0        0   \n",
       "3            0         0      0            0       0        0        0   \n",
       "4            0         0      0            0       0        0        0   \n",
       "\n",
       "   surprise  neutral  \n",
       "0         0        0  \n",
       "1         0        0  \n",
       "2         0        1  \n",
       "3         0        0  \n",
       "4         0        1  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_goemotion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211225"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_goemotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gosentiment = df_goemotion.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_emotions = ['admiration', 'amusement', 'approval', 'caring', 'curiosity', 'desire', 'excitement', 'gratitude', 'joy', 'love', 'optimism', 'pride', 'relief']\n",
    "negative_emotions = ['anger', 'annoyance', 'disappointment', 'disapproval', 'disgust', 'fear', 'grief', 'nervousness', 'remorse', 'sadness', 'embarrassment']\n",
    "neutral_emotions = ['neutral', 'confusion', 'realization', 'surprise']\n",
    "\n",
    "df_gosentiment['Positive'] = df_gosentiment[positive_emotions].sum(axis=1).apply(lambda x: min(1, x))\n",
    "df_gosentiment['Negative'] = df_gosentiment[negative_emotions].sum(axis=1).apply(lambda x: min(1, x))\n",
    "df_gosentiment['Neutral'] = df_gosentiment[neutral_emotions].sum(axis=1).apply(lambda x: min(1, x))\n",
    "\n",
    "also_drop_columns = ['subreddit', 'id', 'link_id', 'author', 'parent_id', 'rater_id']\n",
    "\n",
    "df_gosentiment.drop(labels=positive_emotions + negative_emotions + neutral_emotions + also_drop_columns, axis=1, inplace=True)\n",
    "\n",
    "df_gosentiment['Polarity'] = 0\n",
    "\n",
    "for index, row in df_gosentiment.iterrows():\n",
    "    if row['Positive'] == 1:\n",
    "        df_gosentiment.at[index, 'Polarity'] = 1\n",
    "    elif row['Negative'] == 1:\n",
    "        df_gosentiment.at[index, 'Polarity'] = -1\n",
    "\n",
    "df_gosentiment = df_gosentiment.astype({\n",
    "    'Positive': 'int',\n",
    "    'Negative': 'int',\n",
    "    'Neutral': 'int',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>example_very_unclear</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>1.548381e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;sexuality shouldn’t be a grouping category I...</td>\n",
       "      <td>1.548084e+09</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You do right, if you don't care then fuck 'em!</td>\n",
       "      <td>1.546428e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man I love reddit.</td>\n",
       "      <td>1.547965e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[NAME] was nowhere near them, he was by the Fa...</td>\n",
       "      <td>1.546669e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Right? Considering it’s such an important docu...</td>\n",
       "      <td>1.548280e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>He isn't as big, but he's still quite popular....</td>\n",
       "      <td>1.546320e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>That's crazy; I went to a super [RELIGION] hig...</td>\n",
       "      <td>1.546536e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>that's adorable asf</td>\n",
       "      <td>1.548764e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Sponge Blurb Pubs Quaw Haha GURR ha AAa!\" fin...</td>\n",
       "      <td>1.546984e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I have, and now that you mention it, I think t...</td>\n",
       "      <td>1.546658e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I wanted to downvote this, but it's not your f...</td>\n",
       "      <td>1.547580e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BUT IT'S HER TURN! /s</td>\n",
       "      <td>1.548720e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>That is odd.</td>\n",
       "      <td>1.547736e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Build a wall? /jk</td>\n",
       "      <td>1.547208e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I appreciate it, that's good to know. I hope I...</td>\n",
       "      <td>1.546372e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>One time my 1 stopped right in 91st, I was abl...</td>\n",
       "      <td>1.546881e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Well then I’d say you have a pretty good chanc...</td>\n",
       "      <td>1.546963e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pretty much every Punjabi dude I've met.</td>\n",
       "      <td>1.546613e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>For extra measure tape it right by your crotch...</td>\n",
       "      <td>1.546641e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text   created_utc  \\\n",
       "0                                     That game hurt.  1.548381e+09   \n",
       "1    >sexuality shouldn’t be a grouping category I...  1.548084e+09   \n",
       "2      You do right, if you don't care then fuck 'em!  1.546428e+09   \n",
       "3                                  Man I love reddit.  1.547965e+09   \n",
       "4   [NAME] was nowhere near them, he was by the Fa...  1.546669e+09   \n",
       "5   Right? Considering it’s such an important docu...  1.548280e+09   \n",
       "6   He isn't as big, but he's still quite popular....  1.546320e+09   \n",
       "7   That's crazy; I went to a super [RELIGION] hig...  1.546536e+09   \n",
       "8                                 that's adorable asf  1.548764e+09   \n",
       "9   \"Sponge Blurb Pubs Quaw Haha GURR ha AAa!\" fin...  1.546984e+09   \n",
       "10  I have, and now that you mention it, I think t...  1.546658e+09   \n",
       "11  I wanted to downvote this, but it's not your f...  1.547580e+09   \n",
       "12                              BUT IT'S HER TURN! /s  1.548720e+09   \n",
       "13                                       That is odd.  1.547736e+09   \n",
       "14                                  Build a wall? /jk  1.547208e+09   \n",
       "15  I appreciate it, that's good to know. I hope I...  1.546372e+09   \n",
       "16  One time my 1 stopped right in 91st, I was abl...  1.546881e+09   \n",
       "17  Well then I’d say you have a pretty good chanc...  1.546963e+09   \n",
       "18           Pretty much every Punjabi dude I've met.  1.546613e+09   \n",
       "19  For extra measure tape it right by your crotch...  1.546641e+09   \n",
       "\n",
       "    example_very_unclear  Positive  Negative  Neutral  Polarity  \n",
       "0                  False         0         1        0        -1  \n",
       "1                   True         0         0        0         0  \n",
       "2                  False         0         0        1         0  \n",
       "3                  False         1         0        0         1  \n",
       "4                  False         0         0        1         0  \n",
       "5                  False         1         0        0         1  \n",
       "6                  False         0         1        0        -1  \n",
       "7                  False         1         0        0         1  \n",
       "8                  False         1         0        0         1  \n",
       "9                  False         1         0        0         1  \n",
       "10                 False         0         0        1         0  \n",
       "11                 False         0         1        0        -1  \n",
       "12                 False         0         0        1         0  \n",
       "13                 False         0         1        0        -1  \n",
       "14                 False         0         0        1         0  \n",
       "15                 False         1         0        0         1  \n",
       "16                 False         0         0        1         0  \n",
       "17                 False         0         0        1         0  \n",
       "18                 False         1         0        0         1  \n",
       "19                 False         0         1        0        -1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gosentiment.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NRC Emotion Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.abspath('data/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt'), 'r') as f:\n",
    "#     lines = f.readlines()\n",
    "#     for line in lines:\n",
    "#         word, emotion, \n",
    "\n",
    "nrc_df = pd.read_csv(os.path.abspath('data/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt'), sep='\\t', header=0, names=['word', 'emotion', 'intensity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nrc_dict = {}\n",
    "\n",
    "# # Iterate over nrc_df\n",
    "# for index, row in nrc_df.iterrows():\n",
    "#     # Get the word and emotion\n",
    "#     word = row['word']\n",
    "#     emotion = row['emotion']\n",
    "#     intensity = row['intensity']\n",
    "#     # If the word is not in the dict yet\n",
    "#     if word not in nrc_dict:\n",
    "#         # Initialize the word in the dict\n",
    "#         nrc_dict[word] = []\n",
    "#     # Add the emotion to the word\n",
    "#     if intensity == 1:\n",
    "#         nrc_dict[word].append(emotion)\n",
    "\n",
    "# # Writee nrc_dict to file\n",
    "# with open(os.path.abspath('data/nrc_emotion_lexicon_dict.json'), 'w') as f:\n",
    "#     f.write(json.dumps(nrc_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrc_dict = json.load(open(os.path.abspath('data/nrc_emotion_lexicon_dict.json')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bitcoin Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Sentence Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Word embeddings\n",
    "- PoS\n",
    "- Positive/Neutral word 000110110"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RepresentationModel(\n",
    "#     model_type=\"bert\",\n",
    "#     model_name=\"bert-base-uncased\",\n",
    "#     use_cuda=False\n",
    "# )\n",
    "\n",
    "# model = RepresentationModel(\n",
    "#     model_type=\"roberta\",\n",
    "#     model_name=\"roberta-base\",\n",
    "#     use_cuda=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_path = os.path.abspath('data/GoogleNews-vectors-negative300.bin')\n",
    "word_embedding_model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_path, binary=True, limit=750000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_word2vec_from_scratch(sentences):\n",
    "    # return gensim.models.Word2Vec(sentences, size=300, window=5, min_count=5, workers=4)\n",
    "    return sentences\n",
    "\n",
    "def encode_bert(sentences, model):\n",
    "    return model.encode_sentences(sentences, combine_strategy=None)\n",
    "\n",
    "def encode_word2vec(sentences, max_length=MAX_SENTENCE_LENGTH):\n",
    "    model = word_embedding_model\n",
    "\n",
    "    sentences_vector = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sent_vector = []\n",
    "\n",
    "        for token in nlp(sentence):\n",
    "            if token.is_stop or token.is_space or token.is_punct:\n",
    "                continue\n",
    "\n",
    "            lemma = token.lemma_.lower()\n",
    "            if lemma in model:\n",
    "                sent_vector.append(model[lemma])\n",
    "            elif token.text.lower() in model:\n",
    "                sent_vector.append(model[token.text.lower()])\n",
    "            else:\n",
    "                sent_vector.append([0] * 300)\n",
    "        \n",
    "        if len(sent_vector) > max_length:\n",
    "            sent_vector = sent_vector[:max_length]\n",
    "        else:\n",
    "            sent_vector = sent_vector + [[0] * 300] * (max_length - len(sent_vector))\n",
    "\n",
    "        sentences_vector.append(sent_vector)\n",
    "    \n",
    "    return np.array(sentences_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of Speech Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_other_features(sentences, max_length=MAX_SENTENCE_LENGTH, fit_vectorizer=False):    \n",
    "    vectors = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        vector = []\n",
    "\n",
    "        for token in nlp(sentence):\n",
    "            dictionary = {}\n",
    "\n",
    "            if not (token.is_stop or token.is_space or token.is_punct):\n",
    "                dictionary['pos'] = token.pos_\n",
    "                \n",
    "                associated_emotions = nrc_dict.get(token.lemma_, [])\n",
    "\n",
    "                for emotion in associated_emotions:\n",
    "                    dictionary[emotion] = True\n",
    "                \n",
    "                vector.append(dictionary)\n",
    "\n",
    "        if len(vector) > max_length:\n",
    "            vector = vector[:max_length]\n",
    "        else:\n",
    "            vector = vector + [{}] * (max_length - len(vector))\n",
    "\n",
    "        vectors.append(vector)\n",
    "    \n",
    "    print(len(vectors))\n",
    "\n",
    "    if fit_vectorizer:\n",
    "        dict_vectorizer = DictVectorizer()\n",
    "        dict_vectorizer = dict_vectorizer.fit(list(itertools.chain.from_iterable(vectors)))\n",
    "\n",
    "        with open('dict_vectorizer.pkl', 'wb') as f:\n",
    "            pickle.dump(dict_vectorizer, f)\n",
    "    else:\n",
    "        dict_vectorizer = pickle.load(open('dict_vectorizer.pkl', 'rb'))\n",
    "\n",
    "    encoded = []\n",
    "\n",
    "    for vector in vectors:\n",
    "        encoded.append(dict_vectorizer.transform(vector).toarray())\n",
    "    \n",
    "    return np.array(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On GoSentiment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "(60000, 25, 300)\n",
      "(60000, 25, 27)\n",
      "(60000, 25, 327)\n",
      "(60000, 8175)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "sentences = list(df_gosentiment.text)[:TRAINING_SIZE]\n",
    "\n",
    "# sentences = preprocess_tweets(sentences)\n",
    "sentences_embedded = encode_word2vec(sentences)\n",
    "features_embedded = encode_other_features(sentences, fit_vectorizer=True)\n",
    "\n",
    "# Combine sentences_embedded and features_embedded on the third dimension\n",
    "combined_embedded = np.concatenate((sentences_embedded, features_embedded), axis=2)\n",
    "\n",
    "combined_embedded_2d = combined_embedded.reshape(combined_embedded.shape[0], -1) # combined_embedded.reshape(combined_embedded.shape[0], -1)\n",
    "\n",
    "# with open('combined_embedded_gosentiment.pkl', 'wb') as f:\n",
    "#     pickle.dump(combined_embedded_2d, f)\n",
    "\n",
    "print(sentences_embedded.shape)\n",
    "print(features_embedded.shape)\n",
    "print(combined_embedded.shape)\n",
    "print(combined_embedded_2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.49      0.40      0.44      2651\n",
      "           0       0.50      0.53      0.51      4107\n",
      "           1       0.64      0.67      0.66      5242\n",
      "\n",
      "    accuracy                           0.56     12000\n",
      "   macro avg       0.54      0.53      0.54     12000\n",
      "weighted avg       0.56      0.56      0.56     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = df_gosentiment.Polarity.to_list()[:TRAINING_SIZE]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_embedded_2d, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression(solver='newton-cg', multi_class='ovr', max_iter=250)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "with open('LogisticRegression-60000.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('LogisticRegression-60000.pkl', 'rb') as f:\n",
    "#     model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = df_gosentiment.Polarity.to_list()[:TRAINING_SIZE]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(combined_embedded_2d, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# model_2 = SVC(kernel='linear')\n",
    "\n",
    "# model_2.fit(X_train, y_train)\n",
    "\n",
    "# with open('SVCModel-60000.pkl', 'wb') as f:\n",
    "#     pickle.dump(model_2, f)\n",
    "\n",
    "# pred_2 = model_2.predict(X_test)\n",
    "\n",
    "# print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_vader = df_sf_train.sample(frac=0.01).reset_index(drop=True)\n",
    "# df_vader.text = df_vader.text.astype('string')\n",
    "\n",
    "# analyzer = SentimentIntensityAnalyzer()\n",
    "# #Add VADER metrics to dataframe\n",
    "# df_vader['compound'] = [analyzer.polarity_scores(v)['compound'] for v in df_vader['text']]\n",
    "# df_vader['neg'] = [analyzer.polarity_scores(v)['neg'] for v in df_vader['text']]\n",
    "# df_vader['neu'] = [analyzer.polarity_scores(v)['neu'] for v in df_vader['text']]\n",
    "# df_vader['pos'] = [analyzer.polarity_scores(v)['pos'] for v in df_vader['text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bitcoin Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('LogisticRegression-60000.pkl', 'rb') as f:\n",
    "#     model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRYPTO_PATHS = {\n",
    "    'Bitcoin': os.path.abspath('data/reddit-crypto/Bitcoin_12htop100_DailySub_0101_to_0817_PushShift_raw.csv'),\n",
    "    'Dogecoin': os.path.abspath('data/reddit-crypto/doge_12htop100_DailySub_0101_to_0710_PushShift.csv'),\n",
    "    'Solana': os.path.abspath('data/reddit-crypto/Solana_12htop100_DailySub_0101_to_0817_PushShift_raw.csv'),\n",
    "    'Shiba': os.path.abspath('data/reddit-crypto/Shiba_Inu_12htop100_DailySub_0101_to_0817_PushShift_raw.csv')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df = pd.read_csv(CRYPTO_PATHS['Bitcoin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42088"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reddit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df = reddit_df[reddit_df.selftext != '[removed]']\n",
    "\n",
    "reddit_df.title.fillna('', inplace=True)\n",
    "reddit_df.selftext.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get number of rows per day\n",
    "# reddit_df.groupby('date', as_index=False)['title'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df['fulltext'] = reddit_df.title + ': ' + reddit_df.selftext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df.fulltext = reddit_df.fulltext.apply(preprocess_reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty from fulltext\n",
    "reddit_df.fulltext = reddit_df.fulltext.astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>full_link</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>author</th>\n",
       "      <th>id</th>\n",
       "      <th>permalink</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>fulltext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Habt ihr Literatueempfehlungen um sich in kryp...</td>\n",
       "      <td>Finanzen</td>\n",
       "      <td>Suche gute Bücher etc. zu Kryptowährungen (nic...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/Finanzen/comments/kog...</td>\n",
       "      <td>Investieren</td>\n",
       "      <td>True_Divide5477</td>\n",
       "      <td>kogyn0</td>\n",
       "      <td>/r/Finanzen/comments/kogyn0/habt_ihr_literatue...</td>\n",
       "      <td>https://www.reddit.com/r/Finanzen/comments/kog...</td>\n",
       "      <td>42</td>\n",
       "      <td>Habt ihr Literatueempfehlungen um sich in kryp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Ethereum or bitcoin?</td>\n",
       "      <td>binance</td>\n",
       "      <td>Hi, I have a question that's maybe kind of dum...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/binance/comments/koex...</td>\n",
       "      <td>General</td>\n",
       "      <td>Unknown_Investor</td>\n",
       "      <td>koexj2</td>\n",
       "      <td>/r/binance/comments/koexj2/ethereum_or_bitcoin/</td>\n",
       "      <td>https://www.reddit.com/r/binance/comments/koex...</td>\n",
       "      <td>7</td>\n",
       "      <td>Ethereum or bitcoin?: Hi, I have a question th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>I want some help</td>\n",
       "      <td>wirexappofficial</td>\n",
       "      <td>Guys what is the exchange rate for bitcoin i t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/wirexappofficial/comm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pelllos</td>\n",
       "      <td>ko8lq4</td>\n",
       "      <td>/r/wirexappofficial/comments/ko8lq4/i_want_som...</td>\n",
       "      <td>https://www.reddit.com/r/wirexappofficial/comm...</td>\n",
       "      <td>3</td>\n",
       "      <td>I want some help: Guys what is the exchange ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Buying Bitcoin in Revolut</td>\n",
       "      <td>BitcoinBeginners</td>\n",
       "      <td>Do you recommend buying bitcoin in Revolut in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/BitcoinBeginners/comm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nevermindera</td>\n",
       "      <td>kogkf8</td>\n",
       "      <td>/r/BitcoinBeginners/comments/kogkf8/buying_bit...</td>\n",
       "      <td>https://www.reddit.com/r/BitcoinBeginners/comm...</td>\n",
       "      <td>13</td>\n",
       "      <td>Buying Bitcoin in Revolut: Do you recommend bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Top 15 Cryptocurrency by Market Capitalization...</td>\n",
       "      <td>IOTAmarkets</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/IOTAmarkets/comments/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>accappatoiviola</td>\n",
       "      <td>kog7yv</td>\n",
       "      <td>/r/IOTAmarkets/comments/kog7yv/top_15_cryptocu...</td>\n",
       "      <td>https://youtu.be/71ExZk1YWWE</td>\n",
       "      <td>5</td>\n",
       "      <td>Top 15 Cryptocurrency by Market Capitalization...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>What will be the point of Monero when all futu...</td>\n",
       "      <td>Monero</td>\n",
       "      <td>I understand the argument for Monero now since...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/Monero/comments/kodpv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>r-bitcoin</td>\n",
       "      <td>kodpv4</td>\n",
       "      <td>/r/Monero/comments/kodpv4/what_will_be_the_poi...</td>\n",
       "      <td>https://www.reddit.com/r/Monero/comments/kodpv...</td>\n",
       "      <td>19</td>\n",
       "      <td>What will be the point of Monero when all futu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>BCH Merchant Adoptions</td>\n",
       "      <td>btc</td>\n",
       "      <td>Hey all,  \\nAs I continue to be a BCH ambassad...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/btc/comments/kof6xw/b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>shanytc</td>\n",
       "      <td>kof6xw</td>\n",
       "      <td>/r/btc/comments/kof6xw/bch_merchant_adoptions/</td>\n",
       "      <td>https://www.reddit.com/r/btc/comments/kof6xw/b...</td>\n",
       "      <td>18</td>\n",
       "      <td>BCH Merchant Adoptions: Hey all, As I continue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Can’t receive Crypto to Shakepay from external...</td>\n",
       "      <td>BitcoinCA</td>\n",
       "      <td>Trying to move some BTC to sell \\n\\nMobile app...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/BitcoinCA/comments/ko...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alanpartridge69</td>\n",
       "      <td>ko3ate</td>\n",
       "      <td>/r/BitcoinCA/comments/ko3ate/cant_receive_cryp...</td>\n",
       "      <td>https://www.reddit.com/r/BitcoinCA/comments/ko...</td>\n",
       "      <td>7</td>\n",
       "      <td>Can’t receive Crypto to Shakepay from external...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Tony has said that he looks at players like \"S...</td>\n",
       "      <td>survivor</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/survivor/comments/kog...</td>\n",
       "      <td>Meme</td>\n",
       "      <td>mysteryfan420</td>\n",
       "      <td>kog6lb</td>\n",
       "      <td>/r/survivor/comments/kog6lb/tony_has_said_that...</td>\n",
       "      <td>https://i.redd.it/37dlv8gpkr861.png</td>\n",
       "      <td>6</td>\n",
       "      <td>Tony has said that he looks at players like \"S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Redditors who have asked their employers to pa...</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/Bitcoin/comments/kolm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thebrazengeek</td>\n",
       "      <td>kolmrl</td>\n",
       "      <td>/r/Bitcoin/comments/kolmrl/redditors_who_have_...</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/ko...</td>\n",
       "      <td>15</td>\n",
       "      <td>Redditors who have asked their employers to pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                              title  \\\n",
       "0  2021-01-01  Habt ihr Literatueempfehlungen um sich in kryp...   \n",
       "1  2021-01-01                               Ethereum or bitcoin?   \n",
       "2  2021-01-01                                   I want some help   \n",
       "3  2021-01-01                          Buying Bitcoin in Revolut   \n",
       "4  2021-01-01  Top 15 Cryptocurrency by Market Capitalization...   \n",
       "5  2021-01-01  What will be the point of Monero when all futu...   \n",
       "6  2021-01-01                             BCH Merchant Adoptions   \n",
       "7  2021-01-01  Can’t receive Crypto to Shakepay from external...   \n",
       "8  2021-01-01  Tony has said that he looks at players like \"S...   \n",
       "9  2021-01-01  Redditors who have asked their employers to pa...   \n",
       "\n",
       "          subreddit                                           selftext  score  \\\n",
       "0          Finanzen  Suche gute Bücher etc. zu Kryptowährungen (nic...      1   \n",
       "1           binance  Hi, I have a question that's maybe kind of dum...      1   \n",
       "2  wirexappofficial  Guys what is the exchange rate for bitcoin i t...      1   \n",
       "3  BitcoinBeginners  Do you recommend buying bitcoin in Revolut in ...      1   \n",
       "4       IOTAmarkets                                                         1   \n",
       "5            Monero  I understand the argument for Monero now since...      1   \n",
       "6               btc  Hey all,  \\nAs I continue to be a BCH ambassad...      1   \n",
       "7         BitcoinCA  Trying to move some BTC to sell \\n\\nMobile app...      1   \n",
       "8          survivor                                                         1   \n",
       "9           Bitcoin                                                         1   \n",
       "\n",
       "   upvote_ratio  total_awards_received  \\\n",
       "0           1.0                      0   \n",
       "1           1.0                      0   \n",
       "2           1.0                      0   \n",
       "3           1.0                      0   \n",
       "4           1.0                      0   \n",
       "5           1.0                      0   \n",
       "6           1.0                      0   \n",
       "7           1.0                      0   \n",
       "8           1.0                      0   \n",
       "9           1.0                      0   \n",
       "\n",
       "                                           full_link link_flair_text  \\\n",
       "0  https://www.reddit.com/r/Finanzen/comments/kog...     Investieren   \n",
       "1  https://www.reddit.com/r/binance/comments/koex...         General   \n",
       "2  https://www.reddit.com/r/wirexappofficial/comm...             NaN   \n",
       "3  https://www.reddit.com/r/BitcoinBeginners/comm...             NaN   \n",
       "4  https://www.reddit.com/r/IOTAmarkets/comments/...             NaN   \n",
       "5  https://www.reddit.com/r/Monero/comments/kodpv...             NaN   \n",
       "6  https://www.reddit.com/r/btc/comments/kof6xw/b...             NaN   \n",
       "7  https://www.reddit.com/r/BitcoinCA/comments/ko...             NaN   \n",
       "8  https://www.reddit.com/r/survivor/comments/kog...            Meme   \n",
       "9  https://www.reddit.com/r/Bitcoin/comments/kolm...             NaN   \n",
       "\n",
       "             author      id  \\\n",
       "0   True_Divide5477  kogyn0   \n",
       "1  Unknown_Investor  koexj2   \n",
       "2           pelllos  ko8lq4   \n",
       "3      nevermindera  kogkf8   \n",
       "4   accappatoiviola  kog7yv   \n",
       "5         r-bitcoin  kodpv4   \n",
       "6           shanytc  kof6xw   \n",
       "7   alanpartridge69  ko3ate   \n",
       "8     mysteryfan420  kog6lb   \n",
       "9     thebrazengeek  kolmrl   \n",
       "\n",
       "                                           permalink  \\\n",
       "0  /r/Finanzen/comments/kogyn0/habt_ihr_literatue...   \n",
       "1    /r/binance/comments/koexj2/ethereum_or_bitcoin/   \n",
       "2  /r/wirexappofficial/comments/ko8lq4/i_want_som...   \n",
       "3  /r/BitcoinBeginners/comments/kogkf8/buying_bit...   \n",
       "4  /r/IOTAmarkets/comments/kog7yv/top_15_cryptocu...   \n",
       "5  /r/Monero/comments/kodpv4/what_will_be_the_poi...   \n",
       "6     /r/btc/comments/kof6xw/bch_merchant_adoptions/   \n",
       "7  /r/BitcoinCA/comments/ko3ate/cant_receive_cryp...   \n",
       "8  /r/survivor/comments/kog6lb/tony_has_said_that...   \n",
       "9  /r/Bitcoin/comments/kolmrl/redditors_who_have_...   \n",
       "\n",
       "                                                 url  num_comments  \\\n",
       "0  https://www.reddit.com/r/Finanzen/comments/kog...            42   \n",
       "1  https://www.reddit.com/r/binance/comments/koex...             7   \n",
       "2  https://www.reddit.com/r/wirexappofficial/comm...             3   \n",
       "3  https://www.reddit.com/r/BitcoinBeginners/comm...            13   \n",
       "4                       https://youtu.be/71ExZk1YWWE             5   \n",
       "5  https://www.reddit.com/r/Monero/comments/kodpv...            19   \n",
       "6  https://www.reddit.com/r/btc/comments/kof6xw/b...            18   \n",
       "7  https://www.reddit.com/r/BitcoinCA/comments/ko...             7   \n",
       "8                https://i.redd.it/37dlv8gpkr861.png             6   \n",
       "9  https://www.reddit.com/r/AskReddit/comments/ko...            15   \n",
       "\n",
       "                                            fulltext  \n",
       "0  Habt ihr Literatueempfehlungen um sich in kryp...  \n",
       "1  Ethereum or bitcoin?: Hi, I have a question th...  \n",
       "2  I want some help: Guys what is the exchange ra...  \n",
       "3  Buying Bitcoin in Revolut: Do you recommend bu...  \n",
       "4  Top 15 Cryptocurrency by Market Capitalization...  \n",
       "5  What will be the point of Monero when all futu...  \n",
       "6  BCH Merchant Adoptions: Hey all, As I continue...  \n",
       "7  Can’t receive Crypto to Shakepay from external...  \n",
       "8  Tony has said that he looks at players like \"S...  \n",
       "9  Redditors who have asked their employers to pa...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39757\n",
      "(39757, 25, 300)\n",
      "(39757, 25, 27)\n",
      "(39757, 25, 327)\n",
      "(39757, 8175)\n"
     ]
    }
   ],
   "source": [
    "sentences = list(reddit_df.fulltext)\n",
    "sentences_embedded = encode_word2vec(sentences)\n",
    "features_embedded = encode_other_features(sentences)\n",
    "\n",
    "# Combine sentences_embedded and features_embedded on the third dimension\n",
    "combined_embedded = np.concatenate((sentences_embedded, features_embedded), axis=2)\n",
    "\n",
    "combined_embedded_2d = combined_embedded.reshape(combined_embedded.shape[0], -1) # combined_embedded.reshape(combined_embedded.shape[0], -1)\n",
    "\n",
    "with open('combined_embedded_bitcoinreddit.pkl', 'wb') as f:\n",
    "    pickle.dump(combined_embedded_2d, f)\n",
    "\n",
    "print(sentences_embedded.shape)\n",
    "print(features_embedded.shape)\n",
    "print(combined_embedded.shape)\n",
    "print(combined_embedded_2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_sentiment = model.predict(combined_embedded_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df['sentiment'] = list(reddit_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df.to_csv(os.path.abspath('data/results/reddit_sentiment.csv'), sep=';', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bitcoin Shiba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df = pd.read_csv(CRYPTO_PATHS['Shiba'])\n",
    "\n",
    "#\n",
    "\n",
    "reddit_df = reddit_df[reddit_df.selftext != '[removed]']\n",
    "\n",
    "reddit_df.title.fillna('', inplace=True)\n",
    "reddit_df.selftext.fillna('', inplace=True)\n",
    "\n",
    "# \n",
    "\n",
    "reddit_df['fulltext'] = reddit_df.title + ': ' + reddit_df.selftext\n",
    "reddit_df.fulltext = reddit_df.fulltext.apply(preprocess_reddit)\n",
    "reddit_df.fulltext = reddit_df.fulltext.astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25700\n",
      "(25700, 25, 300)\n",
      "(25700, 25, 27)\n",
      "(25700, 25, 327)\n",
      "(25700, 8175)\n"
     ]
    }
   ],
   "source": [
    "sentences = list(reddit_df.fulltext)\n",
    "sentences_embedded = encode_word2vec(sentences)\n",
    "features_embedded = encode_other_features(sentences)\n",
    "\n",
    "# Combine sentences_embedded and features_embedded on the third dimension\n",
    "combined_embedded = np.concatenate((sentences_embedded, features_embedded), axis=2)\n",
    "\n",
    "combined_embedded_2d = combined_embedded.reshape(combined_embedded.shape[0], -1)\n",
    "\n",
    "with open('combined_embedded_shibareddit.pkl', 'wb') as f:\n",
    "    pickle.dump(combined_embedded_2d, f)\n",
    "\n",
    "print(sentences_embedded.shape)\n",
    "print(features_embedded.shape)\n",
    "print(combined_embedded.shape)\n",
    "print(combined_embedded_2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_sentiment = model.predict(combined_embedded_2d)\n",
    "\n",
    "reddit_df['sentiment'] = list(reddit_sentiment)\n",
    "\n",
    "reddit_df.to_csv(os.path.abspath('data/results/reddit_shiba_sentiment.csv'), sep=';', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VADER Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.55      0.14      0.22     48037\n",
      "           0       0.43      0.70      0.53     72293\n",
      "           1       0.69      0.62      0.65     90895\n",
      "\n",
      "    accuracy                           0.54    211225\n",
      "   macro avg       0.56      0.48      0.47    211225\n",
      "weighted avg       0.57      0.54      0.51    211225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_gosentiment = pd.read_csv(os.path.abspath('data/gosenedited.csv'))\n",
    "\n",
    "def turn_discrete(x):\n",
    "    if x < -0.67:\n",
    "        return -1\n",
    "    elif x < 0.33:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "df_gosentiment['Compound'] = df_gosentiment['compound'].apply(turn_discrete)\n",
    "\n",
    "Y = list(df_gosentiment.Polarity)\n",
    "pred = list(df_gosentiment.Compound)\n",
    "\n",
    "print(classification_report(Y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "436a260425d2d1f41a03db831630dbba59f84586031c56b41ec9dd7831ec3a5e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('TextMining')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
